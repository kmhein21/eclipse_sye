---
title: "Write Up"
format: html
---

### Methods (Erika): 

We collected data between March 30 and April XX, 2024 by deploying 20 AudioMothTM acoustic recorders throughout St. Lawrence County, New York. All locations were fully within the path of totality for the April 8, 2024 total solar eclipse. The partial eclipse began at 14:11:38, totality began at 15:23:52, maximum eclipse was at 15:25:29, totality ended at 15:27:05 and the partial eclipse ended at 16:35:38 (all times local, times from https://www.timeanddate.com/eclipse/in/@5111484?iso=20240408) for a total eclipse duration of 2 hours 24 minutes with totality lasting 3 minutes and 13 seconds.  

Each AudioMoth was configured to record within four temporal windows on each day of the deployment. The first window was from 05:45 – 07:15 (approximately 30 minutes before to 45 minutes after sunrise), the second from 14:00 to 16:50 (capturing the full period of time each day corresponding to the eclipse on April 8),  third from 19:00 to 20:00 (approximately 30 minutes before and after sunset) and the last from 23:00 to 23:30 (to sample nocturnal sounds). (Table 1.)

#### Table 1. 

```{r}
library(pander)
Times<- c("05:45 - 07:15", "14:00 - 16:50", "19:00- 20:00", "23:00 - 23:30")

Reasoning<- c("30-45 minutes before sunrise", "full period of time corresponding to the eclipse", "~30 minutes before and after sunset", "sample nocturnal activity")

Table1<-cbind(Times, Reasoning)
Table1|>pander()
```


Within each time window, each AudioMoth recorded in a repeated cycle with 55 seconds of recording and 5 seconds to write data for every minute of the recording window (Table 2). Sample rate measures the density of recordings per unit time and therefore the range of frequencies that can be recorded. High sample rates record a higher range of frequencies but take up more space on the microSD card. We selected a sample rate of 96 kHz to capture sound frequencies up to about 48 kHz, which allowed us to capture common bird and amphibian songs and calls as well as at least some insects and bat echolocation sounds. Gain is a measure of the degree to which the microphone amplifies the sound as it is recorded. Higher gain enables detection of quieter sounds but can also result in clipping and distortion. After collecting pilot recordings near wetlands where wood frogs were calling we determined that a gain setting of 4 would help increase our detection of animal sounds. 

#### Table 2. 

```{r}
Parameters<- c("Sample Rate (kHz)", "Gain", "Sleep duration (seconds)", "Recording duration (seconds)")

Setting<-c("96", "Relatively high (4 on a 5 point scale)", "5", "55")

Table2<-cbind(Parameters, Setting)
Table2|> pander()
```



We used ArcGIS Pro (version XXXX, ESRI Incorporated, Redlands, California) to identify areas of forest-wetland interface or forested wetland occurring on public or University-owned land. Our intention was to place the recorders at locations where they could capture the sounds of both forest birds and pond-breeding amphibians (as well as other biotic sounds including any active insects or bats). Due to our northern location within the path of the eclipse in North America, the onset of spring was just beginning. Red-winged blackbirds (Agelaius phoeniceus) had returned to the area and were establishing breeding territories and both wood frogs (Lithobates sylvaticus) and spring peepers (Pseudacris crucifer) had begun to chorus at least 5 days prior to deployment of the recorders. To reduce the time required to deploy units, we located the devices near but out of view of hiking trails and within 20 miles of the St. Lawrence University campus (44.58931027483651º N, -75.1613716006626 º W). 


### Analysis

The analysis of this data uses many packages included "Tidyverse", "hms", "soundecology", "here", and "tuneR"

Using the $'soundecology'$ package we selected 5 specific indices of interest that we believed would be important in understanding the changes in acoustic activity. For all the functions used a specific numerical value was obtained as data was only available for the left channel of the recorder. 
Acoustic Evenness Index:

Index which measures the equality and inequality of sound power distribution in different ranges. This index uses the Gini index of evenness. This index is found using the acoustic_evenness() function in the soundecology package. The specific numerical value used is from subsetting $aei_left. 

Bioacoustic Evenness Index:

Index is a function of the power and freqeuncy range of biotic sound. This is obtained using the bioacoustic_evenness() function in the soundecology package. The specific numerical value used is from subsetting $left_area.  

Acoustic Diverstiy Index:

Index which generates proportions of data within a specific interval that reach above a specified threshold (default -50dBFS). This index is obtained using the acoustic_diversity() function in the soundecology package. The specific numerical value used is from subsetting $left_band_values.  

Acoustic Complexity Index:

Index is a function of the amount of variation within frequency bins of a sample. This index is obtained using the acoustic_complexity() function within the soundecology package. The specific numerical value used is from subsetting $acl_left_vals.  

Biophony: 

Index which calculates the average frequency of biotic sound. This index is obtained as a byproduct from the ndsi() function and the numerical values used is from subsetting $biophony_left. 


Initially we approached the data set in an exploratory manner. Using a couple audiofiles (.WAV) we visualized how the indices would appear in graphics and how we should store the indices. Examples of codes for these graphs are listed below:

```{r}
WAV_0616100_240401<-readWave(here("wav_files/20240401_061600.WAV"))

ACI_01<-acoustic_complexity(WAV_0616100_240401)
ACI_01_val<-ACI_01$aci_fl_left_vals
df_ACI<-as.data.frame(ACI_01$aci_fl_left_vals)

plot(x=1:256, y=ACI_01_val, col="orange", pch=16)

ggplot(data=df_ACI, aes(x=1:256, y=ACI_01$aci_fl_left_vals))+
  geom_line(col="orange")+
  theme_minimal()+
  labs(x = "Time(s)", y = "Acoustic Complexity")


ADI1<-acoustic_diversity(WAV_0616100_240401)

ADI1_lv<-as.data.frame(ADI1$left_band_values)

ggplot(data=ADI1_lv, aes(x=1:10, y=ADI1$left_band_values))+
  geom_point()+
  theme_minimal()
```

After this exploration it seemed imperitive to contain the data we would use into one object, so it could be stored and accessed without having to clean the data in the way we would like. The goal was to obtain the dates, times, and the different indices into one data frame per folder. After preforming this task on a couple .WAV files it was automated into its own function $eclipse_df()$ so it could be uploaded to an HPC and mapped on all our recording folders. In the function initially all indices must be obtained, for single indices this is as simple as saving one value per file into a column. For the two indices that contian multiple values per file we created a for loop that would save only the specific values we wanted ("aci_fl_left_values" for ACI and "left_band_values" for ADI).

```{r}
  ACI_all<-vector("list", length(folder))
  ADI_all<-vector("list", length(folder))
  n<-length(folder)
  for (i in 1:n){
    ACI_all[i]<-(as.data.frame(ACI[[i]]$aci_fl_left_vals))
    ADI_all[i]<-(as.data.frame(ADI[[i]]$left_band_values))
  } 
  multiple<-as_tibble(cbind( ACI_all, ADI_all))
```

These two indices were stored in a separate data frame with list columns. Then both the single and multiple indices could be merged into one messy data frame. The main output of this function is the creation of a clean data frame from this initial messy data frame. The code for this is below: 

```{r}
full|> mutate(biophony = as.numeric(biophony),
                        aei = as.numeric(aei),
                        bei = as.numeric(bei))|>
    separate(paths_date, into = c("date","time_hms"), sep = "_")|>
    separate(time_hms, into = c("time", "wav"), sep = "\\.")|>
    separate(time, into = c("hours", "other"), sep = 2)|>
    separate(other, into = c("min", "sec"), sep = 2)|>
    mutate(date = parse_number(date))|>
    unite("time", c("date", "hours", "min", "sec"), sep = ":")|>
    mutate(time= ymd_hms(time))|>
    select(-wav)|>
    mutate(folder_name = deparse(str_remove(folder, here())))|>
    select(folder_name, everything())
```

This takes a table of indices for a specific folder and creates a correct time variable, selects the columns that we would like, and creates a "folder_name" variable so the data frame can be identified.  

The final output of this function is the creation of an RDS file that can be renamed upon loading into the environment. 








