---
title: "Analyzing Audio Patterns During the 2024 Total Solar Eclipse"
author: "Kaitlin Heintzman"
institute: "St. Lawrence University"
date: April 25, 2025
format:
  revealjs:
    transition: fade
    theme: serif 
    slide-number: true
    footer: "Total Solar Eclipse Sound Analysis"
embed-resources: true
---
```{r}
library(tidyverse)
library(lubridate)
library(hms)
library(forecast)
library(soundecology)
library(here)
library(mgcv)
library(modelr)
library(pander)
library(knitr)
```

```{r}
A001_SD001<-readRDS(here("rds_files/A001_SD001.rds"))
A002_SD013<-readRDS(here("rds_files/A002_SD013.rds"))
A003_SD005<-readRDS(here("rds_files/A003_SD005.rds"))
A004_SD012<-readRDS(here("rds_files/A004_SD012.rds"))
A005_SD002<-readRDS(here("rds_files/A005_SD002.rds"))
A006_SD006<-readRDS(here("rds_files/A006_SD006.rds"))
A007_SD017<-readRDS(here("rds_files/A007_SD017.rds"))
A008_SD007<-readRDS(here("rds_files/A008_SD007.rds"))
A009_SD009<-readRDS(here("rds_files/A009_SD009.rds"))
A010_SD014<-readRDS(here("rds_files/A010_SD014.rds"))
A011_SD018<-readRDS(here("rds_files/A011_SD018.rds"))
A013_SD016<-readRDS(here("rds_files/A013_SD016.rds"))
A014_SD021<-readRDS(here("rds_files/A014_SD021.rds"))
A015_SD010<-readRDS(here("rds_files/A015_SD010.rds"))
A016_SD022<-readRDS(here("rds_files/A016_SD022.rds"))
A017_SD024<-readRDS(here("rds_files/A017_SD024.rds"))
A018_SD011<-readRDS(here("rds_files/A018_SD011.rds"))
A019_SD008<-readRDS(here("rds_files/A019_SD008.rds"))
A021_SD023<-readRDS(here("rds_files/A021_SD023.rds"))
A022_SD019<-readRDS(here("rds_files/A022_SD019.rds"))

eclipse_start<-hms(00,00,14)
eclipse_end<-hms(00,50,16)
```


## Outline

* Introduction
  
* Data Collection 
  
* Data Frame Creation 
  
* Modeling 
  
* Conclusion 

## Introduction {.smaller} 

* Our goal was to look deeper into effects that the total solar eclipse has on wildlife activity. 

* Analyzed audio data using 5 common audiological indices 

* Used Generalized Additive Models to produce visuals to search for temporal patterns

* This was an amazing and unique opportunity to look into such a rare phenomenon and to use data that was collected by SLU faculty. 

<br>

* Inspiration for this analysis was taken from: 

Gerber, J. E., Howard, D., & Quinn, J. E. (2020). Soundscape shifts during the 2017 total solar eclipse: An application of dispersed automated recording units to study ephemeral acoustic events. Biodiversity, 21(1), 41â€“47. https://doi.org/10.1080/14888386.2020.1715834 

## 2024 Total Solar Eclipse 

<div style = "display: flex; align-items: center" >
<div style = "flex: 1; padding-right: 20px">

* April 8th, 2024

* Partial Eclipse from 2:11 to 4:35

* Totality from 3:23 to 3:27

</div>
<div>

<img src = "IMG_7721.jpg" alt = "Image" style = "max-width: 400px"/>



## Audio Recorder Placement {.smaller}


<img src = "audio_moth_deployments.png" width = "300" />


## Data Collection {.smaller}
	  
* Recorders collected audio from March 30th to April 16th

| Times         | Reasoning                                        |
|---------------|--------------------------------------------------|
| 5:45 - 7:15   | 30-45 minutes before sunrise                     |
| 14:00 - 16:00 | full period of time corresponding to the eclipse |
| 19:00 - 20:00 | \~30 minutes before and after sunset             |
| 23:00 - 23:30 | sample nocturnal activity                        |

: {.striped}


<br>

* Recorders sampled 55 seconds on and 5 seconds off

* 20 audio recorders produced a total of 115,610 audio clips (>1 TB)

	  
## Audio Indices {.smaller}

* <span style="background-color: lightgreen; color: black; padding: 2px 4px; border-radius: 3px;">Bioacoustic Index </span> -  Assesses diversity and abundance of biological noise. Gives higher value if there are more different types of sounds in different frequencies (2-8kHz)

* <span style="background-color: coral; color: black; padding: 2px 4px; border-radius: 3px;"> Biophony </span>  - Measures the amount of sound within a certain frequency band

* Acoustic Complexity - Focused on expressing the spatial and temporal complexity in sound by capturing the intensity and frequency shifts across an audio file. 

* Acoustic Diversity - Generates proportions over set intervals to assess evenness and variety in sound distribution 

* Acoustic Evenness - Measure how sound is distributed across frequency bands, assess equality and inequality of the rate that sound is produced from a source

<br>

Villanueva-Rivera LJ, Pijanowski BC (2018). _soundecology: Soundscape Ecology_. R package
  version 1.3.3, <https://CRAN.R-project.org/package=soundecology>.

## Visualize and Youtube 

<https://youtu.be/3dftvaUn--Q> 
	
```{r}
#| echo: false
eclipse_time<-A001_SD001|> filter(hour>= eclipse_start & hour<= eclipse_end)
eclipseonly<-A001_SD001|> filter(hour>= eclipse_start & hour<= eclipse_end)|> filter(day == "2024-04-08")

single_day<-A001_SD001|>filter(day == "2024-04-09")

dawn<- single_day|> filter(hour >= as_hms("05:45:00") & hour <= as_hms("07:15:00"))
eclipse<- single_day|> filter(hour >= as_hms("14:00:00") & hour <= as_hms("16:00:00"))
afternoon<- single_day|> filter(hour >= as_hms("19:00:00") & hour <= as_hms("20:00:00"))
night<- single_day|> filter(hour >= as_hms("23:00:00") & hour <= as_hms("23:30:00"))

ggplot(data = dawn, aes( x = hour, y = bei))+
  geom_rect( aes(xmin = as_hms("05:45:00"), xmax = as_hms("07:15:00"), ymin = 0, ymax = 4), fill = "lightblue1")+
  geom_rect(data = dawn, aes(xmin = as_hms("14:00:00"), xmax = as_hms("16:00:00"), ymin = 0, ymax = 4), fill = "lightblue1")+
  geom_rect(data = dawn, aes(xmin = as_hms("19:00:00"), xmax = as_hms("20:00:00"), ymin = 0, ymax = 4), fill = "lightblue1")+
  geom_rect(data = dawn, aes(xmin = as_hms("23:00:00"), xmax = as_hms("23:30:00"), ymin = 0, ymax = 4), fill = "lightblue1")+
  geom_line(col = "darkblue")+
  geom_line(data = eclipse, aes(x = hour, y = bei), col = "darkblue")+
  geom_line(data = afternoon, aes(x = hour, y = bei), col = "darkblue")+
  geom_line(data = night, aes(x = hour, y = bei), col = "darkblue")+
  theme_minimal(base_size = 30)+
  facet_wrap(~day)+
  labs( title = "Example of Full Pattern", y = "Bioacoustic index")+
  scale_x_continuous(name = "Time", breaks = c(hms(00,45,5), hms(00,00,14), hms(00,00, 19),hms(00,00,23)))
  
```

## Using R and HPC {.smaller}


* Function to take sound files and return cleaned data frame with information needed for analysis 
	 
```{r}
table<- A001_SD001|> mutate(ACI = "<dbl [256]>", ADI = "<dbl [10]>")|>
  select(-ACI_all,-ADI_all)|>
  rename("AudioRecorder" = "folder_name", "bioacoustic" = "bei")|>
  slice(-1)|>
  select(AudioRecorder, time, day, hour, bioacoustic, biophony)

head(table)|>kable(format = "html")|>
  kableExtra::kable_styling(font_size = 18)|>
  kableExtra::kable_classic_2()
```

<br>

* Over a **terabyte** of data

* Due to massive size, we used St. Lawrence's HPC (High-Performance Computer) to run and store our files incrementally. 

* With the HPC, each folder of clips took 10.5 hours to process. 
	
## Generalized Additive Modeling {.smaller}

::: {.callout-tip} 

## Why GAM?
  We can maintain additivity while incorporating non-linear functions!
:::

<br> 

$$ Index \sim spline(hour, by = day) + audio\_recorder+ day$$

* Fit a smoothing function for time, and have it vary by day

* Account for Audio Recorder differences, but treat this as a random effect

* Adjust for overall differences in day 

```{r}
#| echo: false
fullAudio<-rbind(A001_SD001, A002_SD013, A003_SD005, A004_SD012,A005_SD002, A006_SD006, A007_SD017, 
                 A008_SD007, A009_SD009, A010_SD014, A011_SD018, A013_SD016,A014_SD021, A015_SD010, A016_SD022,
                 A017_SD024, A018_SD011, A019_SD008, A021_SD023, A022_SD019)|>
  group_by(folder_name)|>
  mutate(fullACI = sapply(ACI_all,sum))|>
  mutate(fullADI = sapply(ADI_all, sum))


modelEclipse_df<-fullAudio|> mutate(eclipse = ifelse(day == "2024-04-08", 
                                                     "eclipse", 
                                                     "not_eclipse"))|>
  mutate(eclipse = as_factor(eclipse), folder_name = as_factor(folder_name))|>
  mutate(hour_numeric = as.numeric(hour))|>
  filter(hour>= eclipse_start & hour<= eclipse_end &
           day %in% c("2024-04-06", "2024-04-07", "2024-04-08",
                    "2024-04-09", "2024-04-11"))|>
  mutate(day_factor = as.factor(day))|>
  select(hour, hour_numeric, everything())

bei_mod<- mgcv::gam(bei~ s(hour_numeric, by = day_factor)+
                      day_factor + s(folder_name, bs = "re"),
                    data = modelEclipse_df)

```
	
<br> 

* Numerically, the estimated degrees of freedom provided a comparison of line curvature between the days


## Bioacoustic Model Visualization {.smaller}

```{r}
#| echo: false
#| fig-align: center 

partial_begin = tibble(bei = (3.5), biophony = (2.5), fullACI = (1950), 
                       fullADI = (9), aei = (0.7), hour_numeric = hms(38,11,14))
second_df = tibble(bei = (3.5), biophony = (2.5), fullACI = (1950),
                   fullADI = (9), aei = (0.7), hour_numeric = hms(00,45,14))
totality = tibble(bei = (3.5), biophony = (2.5), fullACI = (1950),
                  fullADI = (9), aei = (0.7),  hour_numeric = hms(52,23,15))
fourth_df = tibble(bei = (3.5), biophony = (2.5), fullACI = (1950), 
                   fullADI = (9), aei = (0.7), hour_numeric = hms(00,00,16))
partial_end = tibble(bei = (3.5), biophony = (2.5), fullACI = (1950),
                     fullADI = (9), aei = (0.7), hour_numeric = hms(38,35,16))

grid <- modelEclipse_df |> 
  ungroup() |>
  data_grid(hour_numeric = seq_range(hour_numeric, n = 40), folder_name = "/A014_SD021",
    day_factor = modelEclipse_df |> pull(day_factor) |> levels(),
  )

gam_aug <- broom::augment(bei_mod, newdata = grid)


# visual across the time of eclipse
ggplot(data = gam_aug, aes(x = hour_numeric, y = .fitted)) +
  geom_point(data = modelEclipse_df, aes(y = bei, colour = day_factor), alpha = 0.1) +
  geom_line(aes(color = day_factor), linewidth = 1.5)+
  geom_line(data = subset(gam_aug, day_factor == "2024-04-08"), aes( color = day_factor), linewidth = 3)+
  geom_point(data = totality, aes(x = hour_numeric, y = bei), pch = 15, size = 6)+
  geom_point(data = partial_begin, aes(x = hour_numeric, y = bei), pch = 15, size = 6)+
  geom_point(data = partial_begin, aes(x = hour_numeric, y = bei), size = 4, col = "white")+
  geom_point(x = hms(00,10,14), y = 3.5, size = 2)+
  geom_point(data = second_df, aes(x = hour_numeric, y = bei), pch = 15, size = 6)+
  geom_point(data = second_df, aes(x = hour_numeric, y = bei), size = 4, col = "white")+
  geom_point(x = hms(00,44,14), y = 3.5, size = 3)+
  geom_point(data = fourth_df, aes(x = hour_numeric, y = bei), pch = 15, size = 6)+
  geom_point(data = fourth_df, aes(x = hour_numeric, y = bei), size = 4, col = "white")+
  geom_point(x = hms(00,01,16), y = 3.5, size = 3)+
  geom_point(data = partial_end, aes(x = hour_numeric, y = bei),pch = 15 , size = 6)+
  geom_point(data = partial_end, aes(x = hour_numeric, y = bei), size = 4, col = "white")+
  geom_point(x = hms(00,37,16), y = 3.5, size = 2)+
  scale_colour_viridis_d() +
  theme_minimal(base_size = 30) +
  labs(colour = "eclipse_or_not",
       y = "Bioacoustic Index")+
  guides(color = guide_legend(title = "Date"))+
  scale_x_continuous(name = "Time", breaks = c(eclipse_start, hms(00,00,15), hms(00,00,16), eclipse_end))

```



## Biophony Model Visualization {.smaller}

```{r}
#| echo: false
biophony_mod<- mgcv::gam(biophony~ s(hour_numeric, by = day_factor)+
                      day_factor + s(folder_name, bs = "re")
                    , data = modelEclipse_df)
grid <- modelEclipse_df |> ungroup() |>
  data_grid(hour_numeric = seq_range(hour_numeric, n = 40), folder_name = "/A001_SD001",
            day_factor = modelEclipse_df |> pull(day_factor) |> levels()
  )

gam_aug <- broom::augment(biophony_mod, newdata = grid)

ggplot(data = gam_aug, aes(x = hour_numeric, y = .fitted)) +
  geom_point(data = modelEclipse_df, aes(y = biophony, colour = day_factor), alpha = 0.1) +
  geom_line(aes(colour = day_factor), linewidth = 1.5) +
  geom_line(data = subset(gam_aug, day_factor == "2024-04-08"), aes( color = day_factor), linewidth = 3)+
  geom_point(data = totality, aes(x = hour_numeric, y = biophony), pch = 15, size = 6)+
  geom_point(data = partial_begin, aes(x = hour_numeric, y = biophony), pch = 15, size = 6)+
  geom_point(data = partial_begin, aes(x = hour_numeric, y = biophony), size = 4, col = "white")+
  geom_point(x = hms(00,10,14), y = 2.5, size = 2)+
  geom_point(data = second_df, aes(x = hour_numeric, y = biophony), pch = 15, size = 6)+
  geom_point(data = second_df, aes(x = hour_numeric, y = biophony), size = 4, col = "white")+
  geom_point(x = hms(00,44,14), y = 2.5, size = 3)+
  geom_point(data = fourth_df, aes(x = hour_numeric, y = biophony), pch = 15, size = 6)+
  geom_point(data = fourth_df, aes(x = hour_numeric, y = biophony), size = 4, col = "white")+
  geom_point(x = hms(00,01,16), y = 2.5, size = 3)+
  geom_point(data = partial_end, aes(x = hour_numeric, y = biophony),pch = 15 , size = 6)+
  geom_point(data = partial_end, aes(x = hour_numeric, y = biophony), size = 4, col = "white")+
  geom_point(x = hms(00,37,16), y = 2.5, size = 2)+
  scale_colour_viridis_d() +
  theme_minimal(base_size = 30) +
  labs(colour = "eclipse_or_not",
       y = "Biophony")+
  guides(color = guide_legend(title = "Date"))+
    scale_x_continuous(name = "Time", breaks = c(eclipse_start, hms(00,00,15), hms(00,00,16), eclipse_end))
```


## Findings {.smaller}

* Based on our analysis we observed potential patterns in 3 of our indices:

  + Bioacoustic Index

  + Acoustic Evenness 

  + Acoustic Diversity 
  
<br>

* These indices showed increases or decreases around the time of the eclipse, specifically with variation around the time of totality. 

* This suggests that wildlife is affected by the sudden changes in light that occurred during the solar eclipse or by some other eclipse-driven change. 


## Future Projects

* Accounting for temporal autocorrelation: (Emilia Agostinelli '26)

  + Adding more to the final model 
  
  + Autocorrelation between audio clips 
  
<br>

* What species are being affected:  (Aidan Fauth '26)

  + Identifying the wildlife present in the clips
  
  + Machine learning possibility 
	
## Acknowledgements 

* Thank you to Erika Barthelmess, Jessica Harman ('27), Evelyn Albrecht ('25), and Kelsey Simler ('25) who made this project possible by collecting the data. 
  
* Thank you to the MCSS department and specifically Matt Higham for guiding me through this project.
  
* Special Thanks to Ed Harcourt and Lisa Torrey for assistance in using and understanding the HPC process. 




